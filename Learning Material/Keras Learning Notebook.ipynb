{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAD8CAYAAAABraMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nj4ic9H/bYddKoSkD9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e67278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(221)\n",
    "plt.imshow(X_train[20], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[23], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[42], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[54], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# 60,000 images of 28x28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>26</td>\n",
       "      <td>166</td>\n",
       "      <td>255</td>\n",
       "      <td>247</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>172</td>\n",
       "      <td>253</td>\n",
       "      <td>242</td>\n",
       "      <td>195</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>238</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>219</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>249</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>171</td>\n",
       "      <td>219</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>172</td>\n",
       "      <td>226</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>212</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3    4    5    6    7    8    9  ...   18   19   20   21   22  \\\n",
       "0    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "1    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "2    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "3    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "4    0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "5    0   0   0   0    0    0    0    0    0    0 ...  175   26  166  255  247   \n",
       "6    0   0   0   0    0    0    0    0   30   36 ...  225  172  253  242  195   \n",
       "7    0   0   0   0    0    0    0   49  238  253 ...   93   82   82   56   39   \n",
       "8    0   0   0   0    0    0    0   18  219  253 ...    0    0    0    0    0   \n",
       "9    0   0   0   0    0    0    0    0   80  156 ...    0    0    0    0    0   \n",
       "10   0   0   0   0    0    0    0    0    0   14 ...    0    0    0    0    0   \n",
       "11   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "12   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "13   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "14   0   0   0   0    0    0    0    0    0    0 ...   25    0    0    0    0   \n",
       "15   0   0   0   0    0    0    0    0    0    0 ...  150   27    0    0    0   \n",
       "16   0   0   0   0    0    0    0    0    0    0 ...  253  187    0    0    0   \n",
       "17   0   0   0   0    0    0    0    0    0    0 ...  253  249   64    0    0   \n",
       "18   0   0   0   0    0    0    0    0    0    0 ...  253  207    2    0    0   \n",
       "19   0   0   0   0    0    0    0    0    0    0 ...  250  182    0    0    0   \n",
       "20   0   0   0   0    0    0    0    0    0    0 ...   78    0    0    0    0   \n",
       "21   0   0   0   0    0    0    0    0   23   66 ...    0    0    0    0    0   \n",
       "22   0   0   0   0    0    0   18  171  219  253 ...    0    0    0    0    0   \n",
       "23   0   0   0   0   55  172  226  253  253  253 ...    0    0    0    0    0   \n",
       "24   0   0   0   0  136  253  253  253  212  135 ...    0    0    0    0    0   \n",
       "25   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "26   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "27   0   0   0   0    0    0    0    0    0    0 ...    0    0    0    0    0   \n",
       "\n",
       "     23  24  25  26  27  \n",
       "0     0   0   0   0   0  \n",
       "1     0   0   0   0   0  \n",
       "2     0   0   0   0   0  \n",
       "3     0   0   0   0   0  \n",
       "4     0   0   0   0   0  \n",
       "5   127   0   0   0   0  \n",
       "6    64   0   0   0   0  \n",
       "7     0   0   0   0   0  \n",
       "8     0   0   0   0   0  \n",
       "9     0   0   0   0   0  \n",
       "10    0   0   0   0   0  \n",
       "11    0   0   0   0   0  \n",
       "12    0   0   0   0   0  \n",
       "13    0   0   0   0   0  \n",
       "14    0   0   0   0   0  \n",
       "15    0   0   0   0   0  \n",
       "16    0   0   0   0   0  \n",
       "17    0   0   0   0   0  \n",
       "18    0   0   0   0   0  \n",
       "19    0   0   0   0   0  \n",
       "20    0   0   0   0   0  \n",
       "21    0   0   0   0   0  \n",
       "22    0   0   0   0   0  \n",
       "23    0   0   0   0   0  \n",
       "24    0   0   0   0   0  \n",
       "25    0   0   0   0   0  \n",
       "26    0   0   0   0   0  \n",
       "27    0   0   0   0   0  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_image = pd.DataFrame([list(l) for l in X_train[0]])\n",
    "pd_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 10212010\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Flattens' each image \n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_flatten.shape)\n",
    "print(X_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1. This is for optimizer to converge faster.\n",
    "X_train_flatten = X_train_flatten / 255\n",
    "X_test_flatten = X_test_flatten / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullyconnected_model = Sequential() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Dense Layer** takes a few parameters as input. <br/><br/>\n",
    "**output_dim**: The output dimension of the Dense Layer. In this case, I am using 512. You can think of this as the number of neurons in a layer.<br/><br/>\n",
    "**init**: The initialization function for the weights of the layer.<br/><br/>\n",
    "**activation**: The activation function to be used in the layer. A few options are: relu, tanh, sigmoid, linear, softmax. See https://keras.io/activations/ for more details.<br/><br/>\n",
    "**input_dim**: The shape of the input array. In this case, it will be 784 (28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robshlee/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, input_dim=784, activation=\"relu\", name=\"layer_uno\", kernel_initializer=\"normal\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Dense Layer 1\n",
    "fullyconnected_model.add(Dense(512, input_dim=num_pixels, init='normal', activation = 'relu', name='layer_uno'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robshlee/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", name=\"layer_dos\", kernel_initializer=\"normal\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Dense Layer 2\n",
    "fullyconnected_model.add(Dense(num_classes, init='normal', activation='softmax', name='layer_dos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Keras model needs to be compiled.<br/><br/>\n",
    "A Loss function is an error metric to be minimized. There are a few metrics available in Keras.<br/>\n",
    "-mean_squared_error, mean_absolute_percentage_error, hinge, categorical cross entropy, etc<br/><br/>\n",
    "There are **Optimizers** available in Keras. We are using the Adam in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullyconnected_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras uses scikit-learn style methods to perform training and inference.<br/><br/>\n",
    "A **Fit** function takes the following as input,<br/><br/>\n",
    "-training dataset<br/>\n",
    "-training labels<br/>\n",
    "-validation_data (should be tuple with validation data and labels)<br/>\n",
    "-number of epochs<br/>\n",
    "-batchsize (number of samples per gradient update)<br/>\n",
    "-verbosity (0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.2       ,  0.62352943,  0.99215686,\n",
       "        0.62352943,  0.19607843,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.1882353 ,\n",
       "        0.93333334,  0.98823529,  0.98823529,  0.98823529,  0.92941177,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.21176471,  0.89019608,  0.99215686,  0.98823529,\n",
       "        0.93725491,  0.9137255 ,  0.98823529,  0.22352941,  0.02352941,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.03921569,  0.23529412,  0.87843138,\n",
       "        0.98823529,  0.99215686,  0.98823529,  0.79215688,  0.32941177,\n",
       "        0.98823529,  0.99215686,  0.47843137,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.63921571,  0.98823529,  0.98823529,  0.98823529,  0.99215686,\n",
       "        0.98823529,  0.98823529,  0.3764706 ,  0.74117649,  0.99215686,\n",
       "        0.65490198,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.2       ,  0.93333334,  0.99215686,\n",
       "        0.99215686,  0.74509805,  0.44705883,  0.99215686,  0.89411765,\n",
       "        0.18431373,  0.30980393,  1.        ,  0.65882355,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.1882353 ,\n",
       "        0.93333334,  0.98823529,  0.98823529,  0.7019608 ,  0.04705882,\n",
       "        0.29411766,  0.47450981,  0.08235294,  0.        ,  0.        ,\n",
       "        0.99215686,  0.95294118,  0.19607843,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.14901961,  0.64705884,  0.99215686,  0.9137255 ,\n",
       "        0.81568629,  0.32941177,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.99215686,  0.98823529,\n",
       "        0.64705884,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.02745098,  0.69803923,\n",
       "        0.98823529,  0.94117647,  0.27843139,  0.07450981,  0.10980392,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.99215686,  0.98823529,  0.7647059 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.22352941,  0.98823529,  0.98823529,  0.24705882,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.99215686,\n",
       "        0.98823529,  0.7647059 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.7764706 ,\n",
       "        0.99215686,  0.74509805,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  1.        ,  0.99215686,  0.76862746,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.29803923,  0.96470588,  0.98823529,  0.43921569,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.99215686,  0.98823529,  0.58039218,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.33333334,\n",
       "        0.98823529,  0.90196079,  0.09803922,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.02745098,  0.52941179,  0.99215686,  0.72941178,\n",
       "        0.04705882,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.33333334,  0.98823529,  0.87450981,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.02745098,  0.51372552,\n",
       "        0.98823529,  0.88235295,  0.27843139,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.33333334,  0.98823529,  0.56862748,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.1882353 ,  0.64705884,  0.98823529,  0.67843139,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.33725491,  0.99215686,\n",
       "        0.88235295,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.44705883,  0.93333334,  0.99215686,\n",
       "        0.63529414,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.33333334,  0.98823529,  0.97647059,  0.57254905,\n",
       "        0.1882353 ,  0.11372549,  0.33333334,  0.69803923,  0.88235295,\n",
       "        0.99215686,  0.87450981,  0.65490198,  0.21960784,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.33333334,\n",
       "        0.98823529,  0.98823529,  0.98823529,  0.89803922,  0.84313726,\n",
       "        0.98823529,  0.98823529,  0.98823529,  0.76862746,  0.50980395,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.10980392,  0.78039217,  0.98823529,\n",
       "        0.98823529,  0.99215686,  0.98823529,  0.98823529,  0.9137255 ,\n",
       "        0.56862748,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.09803922,  0.50196081,  0.98823529,  0.99215686,\n",
       "        0.98823529,  0.5529412 ,  0.14509805,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flatten[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robshlee/anaconda3/lib/python3.6/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.3148 - acc: 0.9131 - val_loss: 0.1634 - val_acc: 0.9546\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.1290 - acc: 0.9628 - val_loss: 0.1030 - val_acc: 0.9697\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0863 - acc: 0.9752 - val_loss: 0.0817 - val_acc: 0.9756\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0618 - acc: 0.9824 - val_loss: 0.0768 - val_acc: 0.9762\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0474 - acc: 0.9864 - val_loss: 0.0681 - val_acc: 0.9785\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0351 - acc: 0.9907 - val_loss: 0.0635 - val_acc: 0.9806\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0274 - acc: 0.9932 - val_loss: 0.0631 - val_acc: 0.9799\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0223 - acc: 0.9942 - val_loss: 0.0596 - val_acc: 0.9816\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0163 - acc: 0.9965 - val_loss: 0.0688 - val_acc: 0.9788\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0129 - acc: 0.9973 - val_loss: 0.0597 - val_acc: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11cc1a4a8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullyconnected_model.fit(X_train_flatten, y_train, validation_data=(X_test_flatten, y_test), nb_epoch=10, batch_size=200, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Convolutional Neural Network\n",
    "Now that we have created a benchmark, we turn to CNNs to build our classifier.<br/><br/>\n",
    "Most of the innovations that have happened in computer vision in the past few years are due to using CNNs for image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image from Adam Geitgey's blog\n",
    "# from IPython.display import Image\n",
    "# Image(filename='FeedForward Image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Invariance\n",
    "A Fully Connected Neural Network doesn't understand that moving an object in a picture doesn't make it different. We need to give a Neural Network **Translation Invariance**.<br/><br/>\n",
    "Convolution is the way to do this. It can be achieved in 4 steps.<br/><br/>\n",
    "### Step 1\n",
    "-break image into overlapping image tiles and pass sliding window on the entire image.<br/><br/>\n",
    "-Save result as a seperate, tiny picture tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(filename='tiled_image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "-Feed each image tile into a small neural network. In Feed Forward Neural Network<br/><br/>\n",
    "-Entire image was fed into one neural network. In this approach we will do it for every image tile<br/><br/>\n",
    "-Weights/Gradients will be shared for every single tile in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "We don't want to lose track of the arrangement on the original tiles. So we save result from the processing tile into same grid arrangement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "-Reduce the size of output array by doing downsampling<br/><br/>\n",
    "-Maxpooling is used for downsampling<br/><br/>\n",
    "-You look at a 2x2 square of the array and keep the biggest number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**A Note**: image ordering is different in Tensorflow and Theano. Theano uses nb_sample, channels, height, width. Tensorflow uses nb_sample, height, width, channels if your model doesn't converge, then check image_dim_ordering.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our images are gray scale and the conv2D operation needs a 4D tensor as input (samples, rows, cols, channel), we need to reshape our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "nb_classes = 10 #target number of classes\n",
    "nb_epoch = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "\n",
    "# convolution kernal size\n",
    "kernal_size = (3, 3) #size of 'moving tile'. RBG=(3, 3, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be (samples|width|height|channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution operator for filtering windows of two-dimensional inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robshlee/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1..., padding=\"valid\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Convolution2D(nb_filters, kernal_size[0], kernal_size[1], border_mode='valid', input_shape=(img_rows, img_cols, 1)))\n",
    "cnn_model.add(Activation('relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=pool_size))\n",
    "cnn_model.add(Dropout(0.2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(128))\n",
    "cnn_model.add(Activation('relu'))\n",
    "cnn_model.add(Dense(num_classes))\n",
    "cnn_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robshlee/anaconda3/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  class_weight=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "33s - loss: 0.2868 - acc: 0.9215 - val_loss: 0.0944 - val_acc: 0.9735\n",
      "Epoch 2/10\n",
      "31s - loss: 0.0889 - acc: 0.9735 - val_loss: 0.0627 - val_acc: 0.9803\n",
      "Epoch 3/10\n",
      "33s - loss: 0.0620 - acc: 0.9814 - val_loss: 0.0551 - val_acc: 0.9820\n",
      "Epoch 4/10\n",
      "32s - loss: 0.0501 - acc: 0.9849 - val_loss: 0.0465 - val_acc: 0.9859\n",
      "Epoch 5/10\n",
      "32s - loss: 0.0410 - acc: 0.9874 - val_loss: 0.0474 - val_acc: 0.9843\n",
      "Epoch 6/10\n",
      "30s - loss: 0.0341 - acc: 0.9894 - val_loss: 0.0427 - val_acc: 0.9862\n",
      "Epoch 7/10\n",
      "32s - loss: 0.0278 - acc: 0.9910 - val_loss: 0.0473 - val_acc: 0.9850\n",
      "Epoch 8/10\n",
      "31s - loss: 0.0242 - acc: 0.9927 - val_loss: 0.0373 - val_acc: 0.9876\n",
      "Epoch 9/10\n",
      "32s - loss: 0.0192 - acc: 0.9941 - val_loss: 0.0421 - val_acc: 0.9857\n",
      "Epoch 10/10\n",
      "30s - loss: 0.0169 - acc: 0.9946 - val_loss: 0.0471 - val_acc: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12dd8ae10>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just a single epoch of training produces a significant increase in accuracy!**<br/>\n",
    "Finally let's visualize our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST DataSet is all pre-processed and cleaned up for feeding into deep learning model. Real life cases data is not always this way. So having data pre-processing skills are very important. OpenCV is a good package for image pre-processing. Refer to this link for more details on how image pre-processing can be done.\n",
    "https://github.com/parambharat/sdcnd_helpers/blob/master/image_processing/image_processing_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"782pt\" viewBox=\"0.00 0.00 393.93 782.00\" width=\"394pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 778)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-778 389.9277,-778 389.9277,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5049190384 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5049190384</title>\n",
       "<polygon fill=\"none\" points=\"21.0171,-729.5 21.0171,-773.5 364.9106,-773.5 364.9106,-729.5 21.0171,-729.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109.3052\" y=\"-747.3\">conv2d_1_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"197.5933,-729.5 197.5933,-773.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.4277\" y=\"-758.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"197.5933,-751.5 253.2622,-751.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.4277\" y=\"-736.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"253.2622,-729.5 253.2622,-773.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.0864\" y=\"-758.3\">(None, 28, 28, 1)</text>\n",
       "<polyline fill=\"none\" points=\"253.2622,-751.5 364.9106,-751.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.0864\" y=\"-736.3\">(None, 28, 28, 1)</text>\n",
       "</g>\n",
       "<!-- 5049189768 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5049189768</title>\n",
       "<polygon fill=\"none\" points=\"42.7793,-648.5 42.7793,-692.5 343.1484,-692.5 343.1484,-648.5 42.7793,-648.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-666.3\">conv2d_1: Conv2D</text>\n",
       "<polyline fill=\"none\" points=\"168.8311,-648.5 168.8311,-692.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196.6655\" y=\"-677.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"168.8311,-670.5 224.5,-670.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196.6655\" y=\"-655.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"224.5,-648.5 224.5,-692.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.8242\" y=\"-677.3\">(None, 28, 28, 1)</text>\n",
       "<polyline fill=\"none\" points=\"224.5,-670.5 343.1484,-670.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.8242\" y=\"-655.3\">(None, 26, 26, 32)</text>\n",
       "</g>\n",
       "<!-- 5049190384&#45;&gt;5049189768 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5049190384-&gt;5049189768</title>\n",
       "<path d=\"M192.9639,-729.3664C192.9639,-721.1516 192.9639,-711.6579 192.9639,-702.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.464,-702.6068 192.9639,-692.6068 189.464,-702.6069 196.464,-702.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4539855536 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4539855536</title>\n",
       "<polygon fill=\"none\" points=\"30.3447,-567.5 30.3447,-611.5 355.583,-611.5 355.583,-567.5 30.3447,-567.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-585.3\">activation_1: Activation</text>\n",
       "<polyline fill=\"none\" points=\"181.2656,-567.5 181.2656,-611.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.1001\" y=\"-596.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"181.2656,-589.5 236.9346,-589.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.1001\" y=\"-574.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"236.9346,-567.5 236.9346,-611.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.2588\" y=\"-596.3\">(None, 26, 26, 32)</text>\n",
       "<polyline fill=\"none\" points=\"236.9346,-589.5 355.583,-589.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.2588\" y=\"-574.3\">(None, 26, 26, 32)</text>\n",
       "</g>\n",
       "<!-- 5049189768&#45;&gt;4539855536 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5049189768-&gt;4539855536</title>\n",
       "<path d=\"M192.9639,-648.3664C192.9639,-640.1516 192.9639,-630.6579 192.9639,-621.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.464,-621.6068 192.9639,-611.6068 189.464,-621.6069 196.464,-621.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5040497776 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5040497776</title>\n",
       "<polygon fill=\"none\" points=\"0,-486.5 0,-530.5 385.9277,-530.5 385.9277,-486.5 0,-486.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-504.3\">max_pooling2d_1: MaxPooling2D</text>\n",
       "<polyline fill=\"none\" points=\"211.6104,-486.5 211.6104,-530.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.4448\" y=\"-515.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"211.6104,-508.5 267.2793,-508.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.4448\" y=\"-493.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"267.2793,-486.5 267.2793,-530.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326.6035\" y=\"-515.3\">(None, 26, 26, 32)</text>\n",
       "<polyline fill=\"none\" points=\"267.2793,-508.5 385.9277,-508.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326.6035\" y=\"-493.3\">(None, 13, 13, 32)</text>\n",
       "</g>\n",
       "<!-- 4539855536&#45;&gt;5040497776 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4539855536-&gt;5040497776</title>\n",
       "<path d=\"M192.9639,-567.3664C192.9639,-559.1516 192.9639,-549.6579 192.9639,-540.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.464,-540.6068 192.9639,-530.6068 189.464,-540.6069 196.464,-540.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5000249752 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5000249752</title>\n",
       "<polygon fill=\"none\" points=\"42.0034,-405.5 42.0034,-449.5 343.9243,-449.5 343.9243,-405.5 42.0034,-405.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-423.3\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"169.6069,-405.5 169.6069,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.4414\" y=\"-434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"169.6069,-427.5 225.2759,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.4414\" y=\"-412.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"225.2759,-405.5 225.2759,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.6001\" y=\"-434.3\">(None, 13, 13, 32)</text>\n",
       "<polyline fill=\"none\" points=\"225.2759,-427.5 343.9243,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.6001\" y=\"-412.3\">(None, 13, 13, 32)</text>\n",
       "</g>\n",
       "<!-- 5040497776&#45;&gt;5000249752 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5040497776-&gt;5000249752</title>\n",
       "<path d=\"M192.9639,-486.3664C192.9639,-478.1516 192.9639,-468.6579 192.9639,-459.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.464,-459.6068 192.9639,-449.6068 189.464,-459.6069 196.464,-459.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4872974120 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4872974120</title>\n",
       "<polygon fill=\"none\" points=\"50.1724,-324.5 50.1724,-368.5 335.7554,-368.5 335.7554,-324.5 50.1724,-324.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-342.3\">flatten_1: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"161.438,-324.5 161.438,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"189.2725\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161.438,-346.5 217.1069,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"189.2725\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"217.1069,-324.5 217.1069,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.4312\" y=\"-353.3\">(None, 13, 13, 32)</text>\n",
       "<polyline fill=\"none\" points=\"217.1069,-346.5 335.7554,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.4312\" y=\"-331.3\">(None, 5408)</text>\n",
       "</g>\n",
       "<!-- 5000249752&#45;&gt;4872974120 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5000249752-&gt;4872974120</title>\n",
       "<path d=\"M192.9639,-405.3664C192.9639,-397.1516 192.9639,-387.6579 192.9639,-378.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.464,-378.6068 192.9639,-368.6068 189.464,-378.6069 196.464,-378.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5049191112 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>5049191112</title>\n",
       "<polygon fill=\"none\" points=\"67.6792,-243.5 67.6792,-287.5 318.2485,-287.5 318.2485,-243.5 67.6792,-243.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"119.8052\" y=\"-261.3\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"171.9312,-243.5 171.9312,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.7656\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"171.9312,-265.5 227.6001,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.7656\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"227.6001,-243.5 227.6001,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.9243\" y=\"-272.3\">(None, 5408)</text>\n",
       "<polyline fill=\"none\" points=\"227.6001,-265.5 318.2485,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.9243\" y=\"-250.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 4872974120&#45;&gt;5049191112 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>4872974120-&gt;5049191112</title>\n",
       "<path d=\"M192.9639,-324.3664C192.9639,-316.1516 192.9639,-306.6579 192.9639,-297.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.464,-297.6068 192.9639,-287.6068 189.464,-297.6069 196.464,-297.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4872317808 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>4872317808</title>\n",
       "<polygon fill=\"none\" points=\"47.8447,-162.5 47.8447,-206.5 338.083,-206.5 338.083,-162.5 47.8447,-162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.3052\" y=\"-180.3\">activation_2: Activation</text>\n",
       "<polyline fill=\"none\" points=\"198.7656,-162.5 198.7656,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.6001\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"198.7656,-184.5 254.4346,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.6001\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"254.4346,-162.5 254.4346,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.2588\" y=\"-191.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"254.4346,-184.5 338.083,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.2588\" y=\"-169.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 5049191112&#45;&gt;4872317808 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>5049191112-&gt;4872317808</title>\n",
       "<path d=\"M192.9639,-243.3664C192.9639,-235.1516 192.9639,-225.6579 192.9639,-216.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.464,-216.6068 192.9639,-206.6068 189.464,-216.6069 196.464,-216.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5000128440 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>5000128440</title>\n",
       "<polygon fill=\"none\" points=\"71.1792,-81.5 71.1792,-125.5 314.7485,-125.5 314.7485,-81.5 71.1792,-81.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.3052\" y=\"-99.3\">dense_4: Dense</text>\n",
       "<polyline fill=\"none\" points=\"175.4312,-81.5 175.4312,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.2656\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"175.4312,-103.5 231.1001,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.2656\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"231.1001,-81.5 231.1001,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.9243\" y=\"-110.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"231.1001,-103.5 314.7485,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.9243\" y=\"-88.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 4872317808&#45;&gt;5000128440 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>4872317808-&gt;5000128440</title>\n",
       "<path d=\"M192.9639,-162.3664C192.9639,-154.1516 192.9639,-144.6579 192.9639,-135.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.464,-135.6068 192.9639,-125.6068 189.464,-135.6069 196.464,-135.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5000073400 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>5000073400</title>\n",
       "<polygon fill=\"none\" points=\"51.3447,-.5 51.3447,-44.5 334.583,-44.5 334.583,-.5 51.3447,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126.8052\" y=\"-18.3\">activation_3: Activation</text>\n",
       "<polyline fill=\"none\" points=\"202.2656,-.5 202.2656,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.1001\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"202.2656,-22.5 257.9346,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.1001\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"257.9346,-.5 257.9346,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.2588\" y=\"-29.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"257.9346,-22.5 334.583,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.2588\" y=\"-7.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 5000128440&#45;&gt;5000073400 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>5000128440-&gt;5000073400</title>\n",
       "<path d=\"M192.9639,-81.3664C192.9639,-73.1516 192.9639,-63.6579 192.9639,-54.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.464,-54.6068 192.9639,-44.6068 189.464,-54.6069 196.464,-54.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(cnn_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips and Tricks**<br/><br/>\n",
    "In Andrej Karpathy's words, 'don't be a hero', try to use transfer learning and improve upon existing architectures rather than coming up with your own from scratch. <br/><br/>\n",
    "You need GUPs if you want to work on deep learning. Rent GPU in Amazon or Google cloud compute engine or Azure for training models. It is a good investment to setup your own NVIDIA GPU Machine rather than renting.<br/><br/>\n",
    "Read a lot of papers. Lot of smart people are working on computer vision research and there are a lot of papers coming out everyday.<br/><br/>\n",
    "Follow researchers like Andrej Karpathy, Fei Fei Li, Ian GoodFellow, Francois Chollet, etc then twitter recommendation algorithm should recommend researchers similar to that for keeping track of new papers.<br/><br/>\n",
    "Try implementing algorithms from scratch, it will help you with your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
